#!/bin/bash

#SBATCH --job-name={job_name}            #This is the name of your job
#SBATCH --cpus-per-task={n_cpus}                  #This is the number of cores reserved
#SBATCH --mem-per-cpu={memory_per_cpu}G              #This is the memory reserved per core.

#SBATCH --time={time}     #4-00:00:00    #This is the time that your task will run 01:00:00 or 1-00:00:00
#SBATCH --qos={qos}         #1week      #You will run in this queue 6hours or 1day  or 1week
#SBATCH --array={array}          #1-200%20: This is an array job with 200 tasks with a maximum simultaneous number of 20 tasks

# Paths to STDOUT or STDERR files should be absolute or relative to current working directory
#SBATCH --output=outputs/{output_name}%A_%a.o     #These are the STDOUT and STDERR files #j for jobID
#SBATCH --error=outputs/{output_name}%A_%a.e
#SBATCH --mail-type=END,FAIL,TIME_LIMIT
#SBATCH --mail-user={mail_user}        #You will be notified via email when your task ends or fails

#Remember:
#The variable $TMPDIR points to the local hard disks in the computing nodes.
#The variable $HOME points to your home directory.
#The variable $SLURM_JOBID stores the ID number of your job.


source /scicore/home/donafl00/GROUP/Anaconda3/etc/profile.d/conda.sh
conda init bash
conda activate {conda_env_name}

# Run the corresponding commands from the file commands.cmd one by one
# File should be filled with python correct python location
# e.g. /scicore/home/donafl00/{username}/code/AnimalClass/Scicore/AnimalClass_command_line.py animal_id session_id
$(head -$SLURM_ARRAY_TASK_ID {commands_fname} | tail -1) 